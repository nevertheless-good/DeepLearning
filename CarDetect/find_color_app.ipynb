{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76ecbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb99b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIND_CAR_COLOR:\n",
    "    def __init__(self):\n",
    "        # Model 로드\n",
    "        model_path = 'find_color_model.pt'        \n",
    "        self.model = torch.load(model_path)\n",
    "\n",
    "        # Apple Macbook에서 모델을 CPU가 아닌 MPS(GPU)로 실행하기 위하여\n",
    "        self.mps_device = 'CPU'\n",
    "        if not torch.backends.mps.is_available():\n",
    "            if not torch.backends.mps.is_built():\n",
    "                print(\"MPS not available because the current PyTorch install was not \"\n",
    "                      \"built with MPS enabled.\")\n",
    "            else:\n",
    "                print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                      \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "        else:\n",
    "            self.mps_device = 'MPS'\n",
    "            self.model.to(torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4a6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('find_color_model.pt', map_location=torch.device('mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb5ff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800aa43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 128,  tvt : 41 / 5 / 6\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "batch_size  = 128\n",
    "random_seed = 555\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "## make dataset\n",
    "from torchvision import transforms, datasets\n",
    "data_path = '../EFFICIENTNET_DATA'  # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
    "president_dataset = datasets.ImageFolder(\n",
    "                                data_path,\n",
    "                                transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                ]))\n",
    "## data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "train_idx, tmp_idx = train_test_split(list(range(len(president_dataset))), test_size=0.2, random_state=random_seed)\n",
    "datasets = {}\n",
    "datasets['train'] = Subset(president_dataset, train_idx)\n",
    "tmp_dataset       = Subset(president_dataset, tmp_idx)\n",
    "\n",
    "val_idx, test_idx = train_test_split(list(range(len(tmp_dataset))), test_size=0.5, random_state=random_seed)\n",
    "datasets['valid'] = Subset(tmp_dataset, val_idx)\n",
    "datasets['test']  = Subset(tmp_dataset, test_idx)\n",
    "\n",
    "## data loader 선언\n",
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4)\n",
    "dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "dataloaders['test']  = torch.utils.data.DataLoader(datasets['test'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4)\n",
    "batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n",
    "print('batch_size : %d,  tvt : %d / %d / %d' % (batch_size, batch_num['train'], batch_num['valid'], batch_num['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77da565",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(mode\u001b[38;5;241m=\u001b[39mwas_training);  \u001b[38;5;66;03m# 다시 train모드로\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m## TEST!\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtest_and_visualize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mtest_and_visualize_model\u001b[0;34m(model, phase, num_images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_and_visualize_model\u001b[39m(model, phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# phase = 'train', 'valid', 'test'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     was_training \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'training'"
     ]
    }
   ],
   "source": [
    "def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
    "    # phase = 'train', 'valid', 'test'\n",
    "    \n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
    "\n",
    "            running_loss    += loss.item() * inputs.size(0)\n",
    "            running_corrects+= torch.sum(preds == labels.data)\n",
    "            num_cnt += inputs.size(0)  # batch size\n",
    "\n",
    "    #         if i == 2: break\n",
    "\n",
    "        test_loss = running_loss / num_cnt\n",
    "        test_acc  = running_corrects.double() / num_cnt       \n",
    "        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
    "\n",
    "    # 예시 그림 plot\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)        \n",
    "\n",
    "            # 예시 그림 plot\n",
    "            for j in range(1, num_images+1):\n",
    "                ax = plt.subplot(num_images//2, 2, j)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('%s : %s -> %s'%(\n",
    "                    'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
    "                    class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
    "                imshow(inputs.cpu().data[j])          \n",
    "            if i == 0 : break\n",
    "\n",
    "\n",
    "    model.train(mode=was_training);  # 다시 train모드로\n",
    "    \n",
    "## TEST!\n",
    "test_and_visualize_model(model, phase = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c87614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
