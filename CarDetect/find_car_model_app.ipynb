{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6359778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4196d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_model_name = ['HY_025', 'HY_041', 'HY_042', 'HY_050', 'HY_053', 'HY_054', 'HY_058', 'HY_063', 'HY_064',\n",
    "#                  'HY_067', 'HY_069', 'HY_073', 'HY_083', 'HY_091', 'HY_098', 'HY_099', 'KI_026', 'KI_027',\n",
    "#                  'KI_028', 'KI_029', 'KI_043', 'KI_047', 'KI_051', 'KI_052', 'KI_056', 'KI_057', 'KI_059',\n",
    "#                  'KI_060', 'KI_062', 'KI_065', 'KI_066', 'KI_079']\n",
    "\n",
    "car_model_name = ['HY i30', 'HY ê·¸ëžœì €', 'HY ë„¥ì˜', 'HY ë©•ìŠ¤í¬ë£¨ì¦ˆ', 'HY ë² ë‰´', 'HY ë²¨ë¡œìŠ¤í„°', 'HY ìŠ¤íƒ€ë ‰ìŠ¤',\n",
    "                  'HY ì‚°íƒ€íŽ˜', 'HY ì˜ë‚˜íƒ€', 'HY ì•„ë°˜í…Œ', 'HY ì•„ì´ì˜¤ë‹‰', 'HY ì—‘ì„¼íŠ¸', 'HY ì½”ë‚˜', 'HY íˆ¬ì‹¼',\n",
    "                  'HY íŽ ë¦¬ì„¸ì´ë“œ', 'HY í¬í„°2', 'KI K3', 'KI K5', 'KI K7', 'KI K9', 'KI ë‹ˆë¡œ', 'KI ë ˆì´',\n",
    "                  'KI ëª¨ë‹', 'KI ëª¨í•˜ë¹„', 'KI ë´‰ê³ 3', 'KI ì…€í† ìŠ¤', 'KI ìŠ¤í† ë‹‰', 'KI ìŠ¤íŒ…ì–´', 'KI ìŠ¤í¬í‹°ì§€',\n",
    "                  'KI ì˜ë Œí† ', 'KI ì˜ìš¸', 'KI ì¹´ë‹ˆë°œ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76e2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANPR_11:\n",
    "    def __init__(self):\n",
    "        # Model ë¡œë“œ\n",
    "        model_path = 'best_11.pt'\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                                    path = model_path, \n",
    "                                    force_reload=False)\n",
    "\n",
    "        # Apple Macbookì—ì„œ ëª¨ë¸ì„ CPUê°€ ì•„ë‹Œ MPS(GPU)ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•˜ì—¬\n",
    "        self.mps_device = 'CPU'\n",
    "        if not torch.backends.mps.is_available():\n",
    "            if not torch.backends.mps.is_built():\n",
    "                print(\"MPS not available because the current PyTorch install was not \"\n",
    "                      \"built with MPS enabled.\")\n",
    "            else:\n",
    "                print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                      \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "        else:\n",
    "            self.mps_device = 'MPS'\n",
    "            self.model.to(torch.device(\"mps\"))\n",
    "\n",
    "                \n",
    "    # ë¡œë“œëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ Object Detecting í•œ ê²°ê³¼ (Labels, Coordinates)ë¥¼ Return í•œë‹¤\n",
    "    def find_labels_coordinates(self, img):\n",
    "        results = self.model(img)\n",
    "        return results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]  # labels, coordinates    \n",
    "    \n",
    "    def find_model_name(self, label):\n",
    "        return car_model_name[label]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051e75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANPR_18:\n",
    "    def __init__(self):\n",
    "        # Model ë¡œë“œ\n",
    "        model_path = 'best_18.pt'\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                                    path = model_path, \n",
    "                                    force_reload=False)\n",
    "\n",
    "        # Apple Macbookì—ì„œ ëª¨ë¸ì„ CPUê°€ ì•„ë‹Œ MPS(GPU)ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•˜ì—¬\n",
    "        self.mps_device = 'CPU'\n",
    "        if not torch.backends.mps.is_available():\n",
    "            if not torch.backends.mps.is_built():\n",
    "                print(\"MPS not available because the current PyTorch install was not \"\n",
    "                      \"built with MPS enabled.\")\n",
    "            else:\n",
    "                print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                      \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "        else:\n",
    "            self.mps_device = 'MPS'\n",
    "            self.model.to(torch.device(\"mps\"))\n",
    "\n",
    "                \n",
    "    # ë¡œë“œëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ Object Detecting í•œ ê²°ê³¼ (Labels, Coordinates)ë¥¼ Return í•œë‹¤\n",
    "    def find_labels_coordinates(self, img):\n",
    "        results = self.model(img)\n",
    "        return results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]  # labels, coordinates    \n",
    "    \n",
    "    def find_model_name(self, label):\n",
    "        return car_model_name[label]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b275fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANPR_30:\n",
    "    def __init__(self):\n",
    "        # Model ë¡œë“œ\n",
    "        model_path = 'best_30.pt'\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
    "                                    path = model_path, \n",
    "                                    force_reload=False)\n",
    "\n",
    "        # Apple Macbookì—ì„œ ëª¨ë¸ì„ CPUê°€ ì•„ë‹Œ MPS(GPU)ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•˜ì—¬\n",
    "        self.mps_device = 'CPU'\n",
    "        if not torch.backends.mps.is_available():\n",
    "            if not torch.backends.mps.is_built():\n",
    "                print(\"MPS not available because the current PyTorch install was not \"\n",
    "                      \"built with MPS enabled.\")\n",
    "            else:\n",
    "                print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "                      \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "        else:\n",
    "            self.mps_device = 'MPS'\n",
    "            self.model.to(torch.device(\"mps\"))\n",
    "\n",
    "                \n",
    "    # ë¡œë“œëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ Object Detecting í•œ ê²°ê³¼ (Labels, Coordinates)ë¥¼ Return í•œë‹¤\n",
    "    def find_labels_coordinates(self, img):\n",
    "        results = self.model(img)\n",
    "        return results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]  # labels, coordinates    \n",
    "    \n",
    "    def find_model_name(self, label):\n",
    "        return car_model_name[label]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7adabf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/okchuri/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-12 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7096429 parameters, 0 gradients, 16.0 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in /Users/okchuri/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-12 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7096429 parameters, 0 gradients, 16.0 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in /Users/okchuri/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-12 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7096429 parameters, 0 gradients, 16.0 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# ANPR Class \n",
    "anpr_11 = ANPR_11()\n",
    "anpr_18 = ANPR_18()\n",
    "anpr_30 = ANPR_30()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9240e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6707c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_PATH = \"../TEST_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30156463",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(TEST_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309dd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_11(filename):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_11.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            row = coordinates[i]\n",
    "            x1, y1, x2, y2 = int(row[0].item()*width), int(row[1].item()*height), int(row[2].item()*width), int(row[3].item()*height)\n",
    "            draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "            if ((y1 + y2) / 2) > (height / 2):\n",
    "                draw.text((x1, y1-30),\n",
    "                          anpr_11.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "            else:\n",
    "                draw.text((x1, y2+30),\n",
    "                          anpr_11.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),\n",
    "                          font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "        \n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5071a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_18(filename):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_18.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            row = coordinates[i]\n",
    "            x1, y1, x2, y2 = int(row[0].item()*width), int(row[1].item()*height), int(row[2].item()*width), int(row[3].item()*height)\n",
    "            draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "            if ((y1 + y2) / 2) > (height / 2):\n",
    "                draw.text((x1, y1-30),\n",
    "                          anpr_18.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "            else:\n",
    "                draw.text((x1, y2+30),\n",
    "                          anpr_18.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),\n",
    "                          font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "        \n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f5cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_30(filename):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_30.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            row = coordinates[i]\n",
    "            x1, y1, x2, y2 = int(row[0].item()*width), int(row[1].item()*height), int(row[2].item()*width), int(row[3].item()*height)\n",
    "            draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "            if ((y1 + y2) / 2) > (height / 2):\n",
    "                draw.text((x1, y1-30),\n",
    "                          anpr_30.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "            else:\n",
    "                draw.text((x1, y2+30),\n",
    "                          anpr_30.find_model_name(int(labels[i]))+' ('+str(round(row[4].item(), 3))+')',\n",
    "                          (255,0,0),\n",
    "                          font=font, \n",
    "                          stroke_width=2,\n",
    "                          stroke_fill=\"black\")\n",
    "        \n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebe2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_rectangle(rect1, rect2):\n",
    "    return not (rect1[2] < rect2[0] or rect1[0] > rect2[2] or rect1[1] > rect2[3] or rect1[3] < rect2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150cad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def remain_overlap_rectangle_biggest(l, c, change_prob):\n",
    "    data = []\n",
    "    for i in range(len(l)):\n",
    "        data.append([l[i].item(), c[i][0].item(), c[i][1].item(), c[i][2].item(), c[i][3].item(), c[i][4].item()])\n",
    "    \n",
    "    for a, b in combinations(data, 2):\n",
    "        ra = (a[1], a[2], a[3], a[4])\n",
    "        rb = (b[1], b[2], b[3], b[4])\n",
    "        if overlap_rectangle(ra, rb):\n",
    "            area_a = (a[3] - a[1]) * (a[4] - a[2])\n",
    "            area_b = (b[3] - b[1]) * (b[4] - b[2])\n",
    "            if area_a >= area_b:\n",
    "                b[1], b[2], b[3], b[4] = 0, 0, 0, 0\n",
    "                if change_prob:\n",
    "                    if b[5] > a[5]:\n",
    "                        a[0], a[5] = b[0], b[5]\n",
    "            else:\n",
    "                a[1], a[2], a[3], a[4] = 0, 0, 0, 0\n",
    "                if change_prob:\n",
    "                    if a[5] > b[5]:\n",
    "                        b[0], b[5] = a[0], a[5]\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c7fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_bigger_only_11(filename, chage_prob):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_11.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        new_labels = [1] * len(labels)\n",
    "        \n",
    "        # remove overlap rectangle\n",
    "        data = remain_overlap_rectangle_biggest(labels, coordinates, chage_prob)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            x1, y1, x2, y2 = int(data[i][1]*width), int(data[i][2]*height), int(data[i][3]*width), int(data[i][4]*height)\n",
    "            if x1 !=0 or y1 != 0 or x2 != 0 or y2 != 0:\n",
    "                if data[i][5] >= 0.1:\n",
    "                    draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "                    if ((y1 + y2) / 2) > (height / 2):\n",
    "                        draw.text((x1, y1-30),\n",
    "                                  anpr_11.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "                    else:\n",
    "                        draw.text((x1, y2+30),\n",
    "                                  anpr_11.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "\n",
    "\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a9ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_bigger_only_18(filename, chage_prob):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_18.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        new_labels = [1] * len(labels)\n",
    "        \n",
    "        # remove overlap rectangle\n",
    "        data = remain_overlap_rectangle_biggest(labels, coordinates, chage_prob)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            x1, y1, x2, y2 = int(data[i][1]*width), int(data[i][2]*height), int(data[i][3]*width), int(data[i][4]*height)\n",
    "            if x1 !=0 or y1 != 0 or x2 != 0 or y2 != 0:\n",
    "                if data[i][5] >= 0.1:\n",
    "                    draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "                    if ((y1 + y2) / 2) > (height / 2):\n",
    "                        draw.text((x1, y1-30),\n",
    "                                  anpr_18.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "                    else:\n",
    "                        draw.text((x1, y2+30),\n",
    "                                  anpr_18.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "\n",
    "\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c884f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_car_model_bigger_only_30(filename, chage_prob):\n",
    "    image_path = os.path.join(TEST_IMG_PATH, filename)\n",
    "    \n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    labels, coordinates = anpr_30.find_labels_coordinates(img)\n",
    "    \n",
    "    if len(labels):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"AppleMyungjo.ttf\", 30)\n",
    "        \n",
    "        width, height = img.size[0], img.size[1]\n",
    "        \n",
    "        new_labels = [1] * len(labels)\n",
    "        \n",
    "        # remove overlap rectangle\n",
    "        data = remain_overlap_rectangle_biggest(labels, coordinates, chage_prob)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            x1, y1, x2, y2 = int(data[i][1]*width), int(data[i][2]*height), int(data[i][3]*width), int(data[i][4]*height)\n",
    "            if x1 !=0 or y1 != 0 or x2 != 0 or y2 != 0:\n",
    "                if data[i][5] >= 0.1:\n",
    "                    draw.rectangle((x1,y1,x2,y2), outline=(0,255,0), width = 3)\n",
    "\n",
    "                    if ((y1 + y2) / 2) > (height / 2):\n",
    "                        draw.text((x1, y1-30),\n",
    "                                  anpr_30.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "                    else:\n",
    "                        draw.text((x1, y2+30),\n",
    "                                  anpr_30.find_model_name(int(data[i][0])),\n",
    "                                  (255,0,0),\n",
    "                                  font=font,\n",
    "                                  stroke_width=2,\n",
    "                                  stroke_fill=\"black\")\n",
    "\n",
    "\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1adbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da224e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_11(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "863bd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_18(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac779542",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_30(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92ab4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a870304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca6e9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "832d1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7880c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c96f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88489d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50024995",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_11(filenames[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31b08d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_18(filenames[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a448fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_30(filenames[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49215d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[6], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec1aedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[6], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d9135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[6], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daa3c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[6], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a75e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[6], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc671c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[6], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff7c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b1cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_11(filenames[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91fa6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_18(filenames[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ffeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_30(filenames[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "360d0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[7], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8caf3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[7], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22782087",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[7], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fb9f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_11(filenames[7], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccad4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_18(filenames[7], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4a15dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_car_model_bigger_only_30(filenames[7], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37a6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf9818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48805757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bbca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec2349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07919fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24230b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
