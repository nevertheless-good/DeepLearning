{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fc3919",
   "metadata": {},
   "source": [
    "# 차종인식 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea28289",
   "metadata": {},
   "source": [
    "- 데이터셋 출처: AIHUB의 '차량 외관 영상 데이터' (전체 크기 압축되어 약 80GB)\n",
    "  - https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=554\n",
    "- 사용 데이터 셋: 현대 + 기아의 자료만 사용 (현 환경에서 전체 데이터 사용 불가)\n",
    "- 자료 정리는 Local(Macbook)에서 진행하고, 모델 학습은 Colab에서 진행 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25af78",
   "metadata": {},
   "source": [
    "### Model 동작 방식\n",
    "1. 파트별로 객체탐지 모델\n",
    "2. Crop 된 이미지를 이용하여 색상감지 모델\n",
    "3. Crop 된 이미지를 이용하여 모델/연식 등 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcf15a",
   "metadata": {},
   "source": [
    "### Model 1 (Part 검출 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a7e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "from shutil import copyfile\n",
    "import yaml\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = { \"P00\":\"차량전체\", \"P01\":\"프론트범퍼\", \"P02\":\"리어범퍼\", \"P03\":\"타이어(휠)\", \"P04\":\"A필러\",\n",
    "       \"P05\":\"C필러\", \"P06\":\"사이드미러\", \"P07\":\"앞도어\", \"P08\":\"뒷도어\", \"P09\":\"라디에이터그릴\",\n",
    "       \"P10\":\"헤드램프\", \"P11\":\"리어램프\", \"P12\":\"보닛\", \"P13\":\"트렁크\", \"P14\":\"루프\", }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_yolo_data(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if os.path.isdir(os.path.join(src, filename)):\n",
    "            copy_yolo_data(os.path.join(src, filename), dst)\n",
    "            \n",
    "        if os.path.isfile(os.path.join(src, filename)):\n",
    "            if filename != '.DS_Store':\n",
    "                if os.path.splitext(filename)[1] == '.json':\n",
    "                    copyfile(os.path.join(src, filename),os.path.join(dst+'/annotations', filename))\n",
    "                elif os.path.splitext(filename)[1] == '.jpg':\n",
    "                    copyfile(os.path.join(src, filename),os.path.join(dst+'/images', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac52a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터를 YOLOv5 형식에 맞도록 작업하기 위하여 Copy\n",
    "\n",
    "start = time.time()\n",
    "copy_yolo_data('/Users/okchuri/project/codestates/CP2/Data/train', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train')    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val 데이터를 YOLOv5 형식에 맞도록 작업하기 위하여 Copy\n",
    "\n",
    "start = time.time()\n",
    "copy_yolo_data('/Users/okchuri/project/codestates/CP2/Data/validation', '/Users/okchuri/project/codestates/CP2/YOLO_Data/validation')    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_label(src, dst):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "    \n",
    "    resolution = jess_dict['rawDataInfo']['resolution']\n",
    "    width, height = int(resolution.split('*')[0]), int(resolution.split('*')[1])\n",
    "    \n",
    "    with open(dst, 'w') as f:\n",
    "        for obj in jess_dict['learningDataInfo']['objects']:\n",
    "            classID = obj['classId'].split('.')[0]\n",
    "            cx = (int(obj['coords']['tl']['x']) + int(obj['coords']['tr']['x'])) / 2 / width\n",
    "            cy = (int(obj['coords']['tl']['y']) + int(obj['coords']['bl']['y'])) / 2 / height\n",
    "            w = (int(obj['coords']['tr']['x']) - int(obj['coords']['tl']['x'])) / width\n",
    "            h = (int(obj['coords']['bl']['y']) - int(obj['coords']['tl']['y'])) / height\n",
    "            \n",
    "            txt = str(classID) + ' ' + str(cx) + ' ' + str(cy) + ' ' + str(w) + ' ' + str(h) + '\\n'\n",
    "            \n",
    "            f.write(txt)\n",
    "            \n",
    "def make_part_labels(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                make_part_label(os.path.join(src, filename), dst+os.path.splitext(filename)[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "make_part_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/train/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train/labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb84b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "make_part_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['P00', 'P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'P07',\n",
    "          'P08', 'P09', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = 'car_part.yaml'\n",
    "\n",
    "yaml_data = dict(\n",
    "    path = \"data\",\n",
    "    train = \"train\",\n",
    "    val = \"val\",\n",
    "    nc = len(classes),\n",
    "    names = classes\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e52b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a262ea",
   "metadata": {},
   "source": [
    "### Model 2 (모델명, 년식, 색상: 485 classes) <-- (모델명, 년식, 색상, 트림: 1199 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a43009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = []\n",
    "\n",
    "def get_model_class(src):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "        \n",
    "    rawDataID = jess_dict['rawDataInfo']['rawDataID'][9:21]\n",
    "    if not rawDataID in model_classes:\n",
    "        model_classes.append(rawDataID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ed0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classes(src):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                get_model_class(os.path.join(src, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98d8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 8.469452142715454\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "get_model_classes('/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/annotations/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663d6fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007c383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/okchuri/project/codestates/CP2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e92674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_label(src, dst):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "    \n",
    "    rawDataID = jess_dict['rawDataInfo']['rawDataID'][9:21]\n",
    "    resolution = jess_dict['rawDataInfo']['resolution']\n",
    "    width, height = int(resolution.split('*')[0]), int(resolution.split('*')[1])\n",
    "    \n",
    "    with open(dst, 'w') as f:\n",
    "        for obj in jess_dict['learningDataInfo']['objects']:\n",
    "            cx = (int(obj['coords']['tl']['x']) + int(obj['coords']['tr']['x'])) / 2 / width\n",
    "            cy = (int(obj['coords']['tl']['y']) + int(obj['coords']['bl']['y'])) / 2 / height\n",
    "            w = (int(obj['coords']['tr']['x']) - int(obj['coords']['tl']['x'])) / width\n",
    "            h = (int(obj['coords']['bl']['y']) - int(obj['coords']['tl']['y'])) / height\n",
    "            \n",
    "            txt = str(model_classes.index(rawDataID)) + ' ' + str(cx) + ' ' + str(cy) + ' ' + str(w) + ' ' + str(h) + '\\n'\n",
    "            \n",
    "            f.write(txt)\n",
    "            \n",
    "def make_model_labels(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                make_model_label(os.path.join(src, filename), dst+os.path.splitext(filename)[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f40ffd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 155.56005573272705\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "make_model_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/train/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train/model_labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7a76ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 22.781230926513672\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "make_model_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/val/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/val/model_labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582b7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = 'car_model.yaml'\n",
    "\n",
    "yaml_data = dict(\n",
    "    path = \"data\",\n",
    "    train = \"train\",\n",
    "    val = \"val\",\n",
    "    nc = len(model_classes),\n",
    "    names = model_classes\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cc65b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/car_model.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v6.2-266-g72cad39 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=485\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1   1321530  models.yolo.Detect                      [485, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 8327674 parameters, 8327674 gradients, 20.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels.c\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210813_KI_079_19_GR_A_P_01_064.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210816_KI_028_20_GR_A_P_01_065.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210817_HY_041_19_WH_A_P_01_052.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210819_KI_057_21_BL_A_P_01_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210824_KI_047_19_WH_B_P_01_021.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210903_KI_062_19_WH_C_P_01_002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210904_KI_029_20_BK_C_T_03_023.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210924_HY_067_17_RE_A_T_02_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_211206_KI_047_17_BK_A_T_03_004.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_211210_HY_099_21_BL_A_T_02_012.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m92.3GB RAM required, 8.0/16.0GB available, not caching images ⚠️\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/val/labels.cache\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0m11.7GB RAM required, 6.1/16.0GB available, not caching images ⚠️\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.55 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/0         0G    0.06375    0.06155      0.139        815        640:  ^C\n",
      "Training time: 213483.63\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "!cd ./yolov5 && python train.py --workers 4 --img 640 --batch 64 --epochs 1 --data \"data/car_model.yaml\" --weights yolov5s.pt --cache\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f'Training time: {(end_time - start_time):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fd3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adbba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/car_model.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 7 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 🚀 v6.2-266-g72cad39 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=485\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1   1321530  models.yolo.Detect                      [485, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 8327674 parameters, 8327674 gradients, 20.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels/i\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210813_KI_079_19_GR_A_P_01_064.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210816_KI_028_20_GR_A_P_01_065.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210817_HY_041_19_WH_A_P_01_052.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210819_KI_057_21_BL_A_P_01_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210824_KI_047_19_WH_B_P_01_021.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210903_KI_062_19_WH_C_P_01_002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210904_KI_029_20_BK_C_T_03_023.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210924_HY_067_17_RE_A_T_02_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_211206_KI_047_17_BK_A_T_03_004.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_211210_HY_099_21_BL_A_T_02_012.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels/img.cache\n",
      "^C\n",
      "Fatal Python error: init_import_size: Failed to import the site module\n",
      "Python runtime state: initialized\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 580, in <module>\n",
      "    main()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 567, in main\n",
      "    known_paths = addsitepackages(known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 350, in addsitepackages\n",
      "    addsitedir(sitedir, known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 208, in addsitedir\n",
      "    addpackage(sitedir, name, known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 169, in addpackage\n",
      "    exec(line)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/importlib/util.py\", line 14, in <module>\n",
      "    from contextlib import contextmanager\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/contextlib.py\", line 5, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 633, in <module>\n",
      "    from collections import deque\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/collections/__init__.py\", line 24, in <module>\n",
      "    import heapq as _heapq\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/heapq.py\", line 581, in <module>\n",
      "    from _heapq import *\n",
      "KeyboardInterrupt\n",
      "    main(opt)\n",
      "  File \"train.py\", line 527, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 187, in train\n",
      "    train_loader, dataset = create_dataloader(train_path,\n",
      "  File \"/Users/okchuri/project/codestates/CP2/yolov5/utils/dataloaders.py\", line 144, in create_dataloader\n",
      "    return loader(dataset,\n",
      "  File \"/Users/okchuri/project/codestates/CP2/yolov5/utils/dataloaders.py\", line 164, in __init__\n",
      "    self.iterator = super().__iter__()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1034, in __init__\n",
      "    w.start()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/context.py\", line 284, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 116.70\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "!cd ./yolov5 && python train.py --workers 4 --img 640 --batch 64 --epochs 1 --data \"data/car_model.yaml\" --weights yolov5s.pt\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f'Training time: {(end_time - start_time):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e4497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcfa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
