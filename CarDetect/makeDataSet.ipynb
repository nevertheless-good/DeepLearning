{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fc3919",
   "metadata": {},
   "source": [
    "# ì°¨ì¢…ì¸ì‹ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea28289",
   "metadata": {},
   "source": [
    "- ë°ì´í„°ì…‹ ì¶œì²˜: AIHUBì˜ 'ì°¨ëŸ‰ ì™¸ê´€ ì˜ìƒ ë°ì´í„°' (ì „ì²´ í¬ê¸° ì••ì¶•ë˜ì–´ ì•½ 80GB)\n",
    "  - https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=554\n",
    "- ì‚¬ìš© ë°ì´í„° ì…‹: í˜„ëŒ€ + ê¸°ì•„ì˜ ìë£Œë§Œ ì‚¬ìš© (í˜„ í™˜ê²½ì—ì„œ ì „ì²´ ë°ì´í„° ì‚¬ìš© ë¶ˆê°€)\n",
    "- ìë£Œ ì •ë¦¬ëŠ” Local(Macbook)ì—ì„œ ì§„í–‰í•˜ê³ , ëª¨ë¸ í•™ìŠµì€ Colabì—ì„œ ì§„í–‰ ì˜ˆì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25af78",
   "metadata": {},
   "source": [
    "### Model ë™ì‘ ë°©ì‹\n",
    "1. íŒŒíŠ¸ë³„ë¡œ ê°ì²´íƒì§€ ëª¨ë¸\n",
    "2. Crop ëœ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ ìƒ‰ìƒê°ì§€ ëª¨ë¸\n",
    "3. Crop ëœ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸/ì—°ì‹ ë“± ë¶„ë¥˜ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcf15a",
   "metadata": {},
   "source": [
    "### Model 1 (Part ê²€ì¶œ ëª¨ë¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a7e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "from shutil import copyfile\n",
    "import yaml\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "part = { \"P00\":\"ì°¨ëŸ‰ì „ì²´\", \"P01\":\"í”„ë¡ íŠ¸ë²”í¼\", \"P02\":\"ë¦¬ì–´ë²”í¼\", \"P03\":\"íƒ€ì´ì–´(íœ )\", \"P04\":\"Aí•„ëŸ¬\",\n",
    "       \"P05\":\"Cí•„ëŸ¬\", \"P06\":\"ì‚¬ì´ë“œë¯¸ëŸ¬\", \"P07\":\"ì•ë„ì–´\", \"P08\":\"ë’·ë„ì–´\", \"P09\":\"ë¼ë””ì—ì´í„°ê·¸ë¦´\",\n",
    "       \"P10\":\"í—¤ë“œë¨í”„\", \"P11\":\"ë¦¬ì–´ë¨í”„\", \"P12\":\"ë³´ë‹›\", \"P13\":\"íŠ¸ë í¬\", \"P14\":\"ë£¨í”„\", }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_yolo_data(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if os.path.isdir(os.path.join(src, filename)):\n",
    "            copy_yolo_data(os.path.join(src, filename), dst)\n",
    "            \n",
    "        if os.path.isfile(os.path.join(src, filename)):\n",
    "            if filename != '.DS_Store':\n",
    "                if os.path.splitext(filename)[1] == '.json':\n",
    "                    copyfile(os.path.join(src, filename),os.path.join(dst+'/annotations', filename))\n",
    "                elif os.path.splitext(filename)[1] == '.jpg':\n",
    "                    copyfile(os.path.join(src, filename),os.path.join(dst+'/images', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac52a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ë°ì´í„°ë¥¼ YOLOv5 í˜•ì‹ì— ë§ë„ë¡ ì‘ì—…í•˜ê¸° ìœ„í•˜ì—¬ Copy\n",
    "\n",
    "start = time.time()\n",
    "copy_yolo_data('/Users/okchuri/project/codestates/CP2/Data/train', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train')    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val ë°ì´í„°ë¥¼ YOLOv5 í˜•ì‹ì— ë§ë„ë¡ ì‘ì—…í•˜ê¸° ìœ„í•˜ì—¬ Copy\n",
    "\n",
    "start = time.time()\n",
    "copy_yolo_data('/Users/okchuri/project/codestates/CP2/Data/validation', '/Users/okchuri/project/codestates/CP2/YOLO_Data/validation')    \n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_part_label(src, dst):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "    \n",
    "    resolution = jess_dict['rawDataInfo']['resolution']\n",
    "    width, height = int(resolution.split('*')[0]), int(resolution.split('*')[1])\n",
    "    \n",
    "    with open(dst, 'w') as f:\n",
    "        for obj in jess_dict['learningDataInfo']['objects']:\n",
    "            classID = obj['classId'].split('.')[0]\n",
    "            cx = (int(obj['coords']['tl']['x']) + int(obj['coords']['tr']['x'])) / 2 / width\n",
    "            cy = (int(obj['coords']['tl']['y']) + int(obj['coords']['bl']['y'])) / 2 / height\n",
    "            w = (int(obj['coords']['tr']['x']) - int(obj['coords']['tl']['x'])) / width\n",
    "            h = (int(obj['coords']['bl']['y']) - int(obj['coords']['tl']['y'])) / height\n",
    "            \n",
    "            txt = str(classID) + ' ' + str(cx) + ' ' + str(cy) + ' ' + str(w) + ' ' + str(h) + '\\n'\n",
    "            \n",
    "            f.write(txt)\n",
    "            \n",
    "def make_part_labels(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                make_part_label(os.path.join(src, filename), dst+os.path.splitext(filename)[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "make_part_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/train/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train/labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb84b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "make_part_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['P00', 'P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'P07',\n",
    "          'P08', 'P09', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = 'car_part.yaml'\n",
    "\n",
    "yaml_data = dict(\n",
    "    path = \"data\",\n",
    "    train = \"train\",\n",
    "    val = \"val\",\n",
    "    nc = len(classes),\n",
    "    names = classes\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e52b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a262ea",
   "metadata": {},
   "source": [
    "### Model 2 (ëª¨ë¸ëª…, ë…„ì‹, ìƒ‰ìƒ: 485 classes) <-- (ëª¨ë¸ëª…, ë…„ì‹, ìƒ‰ìƒ, íŠ¸ë¦¼: 1199 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a43009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = []\n",
    "\n",
    "def get_model_class(src):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "        \n",
    "    rawDataID = jess_dict['rawDataInfo']['rawDataID'][9:21]\n",
    "    if not rawDataID in model_classes:\n",
    "        model_classes.append(rawDataID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ed0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classes(src):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                get_model_class(os.path.join(src, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98d8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 8.469452142715454\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "get_model_classes('/Users/okchuri/project/codestates/CP2/YOLO_Data/validation/annotations/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663d6fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007c383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/okchuri/project/codestates/CP2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e92674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_label(src, dst):\n",
    "    with open(src, 'r') as jess:\n",
    "        jess_dict = json.load(jess)\n",
    "    \n",
    "    rawDataID = jess_dict['rawDataInfo']['rawDataID'][9:21]\n",
    "    resolution = jess_dict['rawDataInfo']['resolution']\n",
    "    width, height = int(resolution.split('*')[0]), int(resolution.split('*')[1])\n",
    "    \n",
    "    with open(dst, 'w') as f:\n",
    "        for obj in jess_dict['learningDataInfo']['objects']:\n",
    "            cx = (int(obj['coords']['tl']['x']) + int(obj['coords']['tr']['x'])) / 2 / width\n",
    "            cy = (int(obj['coords']['tl']['y']) + int(obj['coords']['bl']['y'])) / 2 / height\n",
    "            w = (int(obj['coords']['tr']['x']) - int(obj['coords']['tl']['x'])) / width\n",
    "            h = (int(obj['coords']['bl']['y']) - int(obj['coords']['tl']['y'])) / height\n",
    "            \n",
    "            txt = str(model_classes.index(rawDataID)) + ' ' + str(cx) + ' ' + str(cy) + ' ' + str(w) + ' ' + str(h) + '\\n'\n",
    "            \n",
    "            f.write(txt)\n",
    "            \n",
    "def make_model_labels(src, dst):\n",
    "    filenames = os.listdir(src)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename != '.DS_Store':\n",
    "            if os.path.splitext(filename)[1] == '.json':\n",
    "                make_model_label(os.path.join(src, filename), dst+os.path.splitext(filename)[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f40ffd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 155.56005573272705\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "make_model_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/train/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/train/model_labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7a76ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 22.781230926513672\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "make_model_labels('/Users/okchuri/project/codestates/CP2/YOLO_Data/val/annotations/', '/Users/okchuri/project/codestates/CP2/YOLO_Data/val/model_labels/')\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582b7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = 'car_model.yaml'\n",
    "\n",
    "yaml_data = dict(\n",
    "    path = \"data\",\n",
    "    train = \"train\",\n",
    "    val = \"val\",\n",
    "    nc = len(model_classes),\n",
    "    names = model_classes\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cc65b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/car_model.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ğŸš€ v6.2-266-g72cad39 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=485\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1   1321530  models.yolo.Detect                      [485, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 8327674 parameters, 8327674 gradients, 20.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels.c\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210813_KI_079_19_GR_A_P_01_064.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210816_KI_028_20_GR_A_P_01_065.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210817_HY_041_19_WH_A_P_01_052.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210819_KI_057_21_BL_A_P_01_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210824_KI_047_19_WH_B_P_01_021.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210903_KI_062_19_WH_C_P_01_002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210904_KI_029_20_BK_C_T_03_023.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_210924_HY_067_17_RE_A_T_02_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_211206_KI_047_17_BK_A_T_03_004.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/C_211210_HY_099_21_BL_A_T_02_012.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m92.3GB RAM required, 8.0/16.0GB available, not caching images âš ï¸\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/val/labels.cache\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0m11.7GB RAM required, 6.1/16.0GB available, not caching images âš ï¸\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.55 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to runs/train/exp5/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/0         0G    0.06375    0.06155      0.139        815        640:  ^C\n",
      "Training time: 213483.63\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "!cd ./yolov5 && python train.py --workers 4 --img 640 --batch 64 --epochs 1 --data \"data/car_model.yaml\" --weights yolov5s.pt --cache\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f'Training time: {(end_time - start_time):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fd3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adbba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data/car_model.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 7 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 ğŸš€ v6.2-266-g72cad39 Python-3.8.13 torch-1.13.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ğŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=485\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1   1321530  models.yolo.Detect                      [485, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 8327674 parameters, 8327674 gradients, 20.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels/i\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210813_KI_079_19_GR_A_P_01_064.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210816_KI_028_20_GR_A_P_01_065.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210817_HY_041_19_WH_A_P_01_052.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210819_KI_057_21_BL_A_P_01_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210824_KI_047_19_WH_B_P_01_021.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210903_KI_062_19_WH_C_P_01_002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210904_KI_029_20_BK_C_T_03_023.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_210924_HY_067_17_RE_A_T_02_009.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_211206_KI_047_17_BK_A_T_03_004.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /Users/okchuri/project/codestates/CP2/yolov5/data/train/images/img/C_211210_HY_099_21_BL_A_T_02_012.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/okchuri/project/codestates/CP2/yolov5/data/train/labels/img.cache\n",
      "^C\n",
      "Fatal Python error: init_import_size: Failed to import the site module\n",
      "Python runtime state: initialized\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 580, in <module>\n",
      "    main()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 567, in main\n",
      "    known_paths = addsitepackages(known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 350, in addsitepackages\n",
      "    addsitedir(sitedir, known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 208, in addsitedir\n",
      "    addpackage(sitedir, name, known_paths)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site.py\", line 169, in addpackage\n",
      "    exec(line)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/importlib/util.py\", line 14, in <module>\n",
      "    from contextlib import contextmanager\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/contextlib.py\", line 5, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 633, in <module>\n",
      "    from collections import deque\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/collections/__init__.py\", line 24, in <module>\n",
      "    import heapq as _heapq\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/heapq.py\", line 581, in <module>\n",
      "    from _heapq import *\n",
      "KeyboardInterrupt\n",
      "    main(opt)\n",
      "  File \"train.py\", line 527, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 187, in train\n",
      "    train_loader, dataset = create_dataloader(train_path,\n",
      "  File \"/Users/okchuri/project/codestates/CP2/yolov5/utils/dataloaders.py\", line 144, in create_dataloader\n",
      "    return loader(dataset,\n",
      "  File \"/Users/okchuri/project/codestates/CP2/yolov5/utils/dataloaders.py\", line 164, in __init__\n",
      "    self.iterator = super().__iter__()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1034, in __init__\n",
      "    w.start()\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/context.py\", line 284, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
      "    super().__init__(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/Users/okchuri/opt/anaconda3/envs/deepLearning/lib/python3.8/multiprocessing/popen_spawn_posix.py\", line 62, in _launch\n",
      "    f.write(fp.getbuffer())\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 116.70\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "!cd ./yolov5 && python train.py --workers 4 --img 640 --batch 64 --epochs 1 --data \"data/car_model.yaml\" --weights yolov5s.pt\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f'Training time: {(end_time - start_time):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e4497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcfa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71e73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
